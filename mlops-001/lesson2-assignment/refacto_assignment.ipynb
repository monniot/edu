{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.all import *\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.torch_core import set_seed\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=384,\n",
    "    batch_size=16,\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=1, \n",
    "    lr=0.00145,\n",
    "    arch = 0,\n",
    "    pretrained=True,  # whether to use pretrained encoder\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    processed_data_at = wandb.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "    processed_dataset_dir = Path(processed_data_at.download())\n",
    "    return processed_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_record = ObjectDetectionRecord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCocoParser(Parser):\n",
    "    def __init__(self, template_record, data_dir):\n",
    "        super().__init__(template_record=template_record)\n",
    "        self.data_dir = data_dir\n",
    "        annot_dict = json.load(open(data_dir / \"train_sample.json\"))\n",
    "        df = pd.DataFrame(annot_dict[\"annotations\"])\n",
    "        images_corr = pd.DataFrame(annot_dict[\"images\"])\n",
    "        df = df.merge(images_corr, how='left', left_on=\"image_id\", right_on=\"id\")\n",
    "        df.drop(columns=\"id\", inplace=True)\n",
    "        self.df = df\n",
    "        self.add_size()\n",
    "        classes = annot_dict[\"categories\"]\n",
    "        class_map = {c[\"id\"]: c[\"name\"] for c in classes}\n",
    "        self.df[\"category\"] = self.df[\"category_id\"].replace(class_map)\n",
    "        idx_map = {c[\"id\"]: i+1 for i,c in enumerate(classes)}\n",
    "        self.df[\"category_id\"] = self.df[\"category_id\"].replace(idx_map)\n",
    "        classes = [c[\"name\"] for c in classes]\n",
    "        self.class_map = ClassMap(classes)\n",
    "\n",
    "    def __iter__(self) -> Any:\n",
    "        for o in self.df.itertuples():\n",
    "            yield o\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def add_size(self):\n",
    "      image_height = []\n",
    "      image_width = []\n",
    "      for i in self.df.file_name:\n",
    "        image = Image.open(self.data_dir / \"images\" / i)\n",
    "        width, height = image.size\n",
    "        image_height.append(height)\n",
    "        image_width.append(width)\n",
    "      self.df[\"height\"] = image_height\n",
    "      self.df[\"width\"] = image_width\n",
    "\n",
    "    def record_id(self, o) -> Hashable:\n",
    "        return o.file_name\n",
    "\n",
    "    def parse_fields(self, o, record, is_new):\n",
    "        if is_new:\n",
    "            record.set_filepath(self.data_dir / 'images' / o.file_name)\n",
    "            record.set_img_size(ImgSize(width=o.width, height=o.height))\n",
    "            record.detection.set_class_map(self.class_map)\n",
    "\n",
    "        record.detection.add_bboxes([BBox.from_xywh(o.bbox[0], o.bbox[1], o.bbox[2], o.bbox[3])])\n",
    "        record.detection.add_labels([o.category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, bs=4, image_size=384, augment=True):\n",
    "    parser = CustomCocoParser(template_record=template_record, data_dir = data_dir)\n",
    "    # Build Fixed Splitter\n",
    "    splits = pd.read_csv(data_dir / 'data_split.csv')\n",
    "    split_train = splits[splits['Stage']==\"train\"][\"File_Name\"].tolist()\n",
    "    split_val = splits[splits['Stage']==\"val\"][\"File_Name\"].tolist()\n",
    "    split_test = splits[splits['Stage']==\"test\"][\"File_Name\"].tolist()\n",
    "\n",
    "    splitter_list = []\n",
    "    splitter_list.append(split_train)\n",
    "    splitter_list.append(split_val)\n",
    "    splitter_list.append(split_test)\n",
    "\n",
    "    splitter = FixedSplitter(splitter_list)\n",
    "\n",
    "    # Get records\n",
    "    train_records, valid_records, test_records = parser.parse(data_splitter=splitter)\n",
    "\n",
    "    # Transforms\n",
    "    # size is set to 384 because EfficientDet requires its inputs to be divisible by 128\n",
    "    train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\n",
    "    valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])\n",
    "    # Datasets\n",
    "    train_ds = Dataset(train_records, train_tfms)\n",
    "    valid_ds = Dataset(valid_records, valid_tfms)\n",
    "    return train_ds, valid_ds , parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(selection, image_size):\n",
    "    extra_args = {}\n",
    "\n",
    "    if selection == 0:\n",
    "        model_type = models.mmdet.vfnet\n",
    "        backbone = model_type.backbones.resnet50_fpn_mstrain_2x\n",
    "\n",
    "    if selection == 1:\n",
    "        model_type = models.mmdet.retinanet\n",
    "        backbone = model_type.backbones.resnet50_fpn_1x\n",
    "        # extra_args['cfg_options'] = { \n",
    "        #   'model.bbox_head.loss_bbox.loss_weight': 2,\n",
    "        #   'model.bbox_head.loss_cls.loss_weight': 0.8,\n",
    "        #    }\n",
    "\n",
    "    if selection == 2:\n",
    "        model_type = models.mmdet.faster_rcnn\n",
    "        backbone = model_type.backbones.resnet101_fpn_2x\n",
    "        # extra_args['cfg_options'] = { \n",
    "        #   'model.roi_head.bbox_head.loss_bbox.loss_weight': 2,\n",
    "        #   'model.roi_head.bbox_head.loss_cls.loss_weight': 0.8,\n",
    "        #    }\n",
    "\n",
    "    if selection == 3:\n",
    "        model_type = models.mmdet.ssd\n",
    "        backbone = model_type.backbones.ssd300\n",
    "\n",
    "    if selection == 4:\n",
    "        model_type = models.mmdet.yolox\n",
    "        backbone = model_type.backbones.yolox_s_8x8\n",
    "\n",
    "    if selection == 5:\n",
    "        model_type = models.mmdet.yolof\n",
    "        backbone = model_type.backbones.yolof_r50_c5_8x8_1x_coco\n",
    "\n",
    "    if selection == 6:\n",
    "        model_type = models.mmdet.detr\n",
    "        backbone = model_type.backbones.r50_8x2_150e_coco\n",
    "\n",
    "    if selection == 7:\n",
    "        model_type = models.mmdet.deformable_detr\n",
    "        backbone = model_type.backbones.twostage_refine_r50_16x2_50e_coco\n",
    "\n",
    "    if selection == 8:\n",
    "        model_type = models.mmdet.fsaf\n",
    "        backbone = model_type.backbones.x101_64x4d_fpn_1x_coco\n",
    "\n",
    "    if selection == 9:\n",
    "        model_type = models.mmdet.sabl\n",
    "        backbone = model_type.backbones.r101_fpn_gn_2x_ms_640_800_coco\n",
    "\n",
    "    if selection == 10:\n",
    "        model_type = models.mmdet.centripetalnet\n",
    "        backbone = model_type.backbones.hourglass104_mstest_16x6_210e_coco\n",
    "\n",
    "    elif selection == 11:\n",
    "    # The Retinanet model is also implemented in the torchvision library\n",
    "        model_type = models.torchvision.retinanet\n",
    "        backbone = model_type.backbones.resnet50_fpn\n",
    "\n",
    "    elif selection == 12:\n",
    "        model_type = models.ross.efficientdet\n",
    "        backbone = model_type.backbones.tf_lite0\n",
    "        # The efficientdet model requires an img_size parameter\n",
    "        extra_args['img_size'] = image_size\n",
    "\n",
    "    elif selection == 13:\n",
    "        model_type = models.ultralytics.yolov5\n",
    "        backbone = model_type.backbones.small\n",
    "        # The yolov5 model requires an img_size parameter\n",
    "        extra_args['img_size'] = image_size\n",
    "\n",
    "    return model_type, backbone, extra_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOMetric_perclass(COCOMetric):\n",
    "   def finalize(self) -> Dict[str, float]:\n",
    "    with CaptureStdout():\n",
    "        coco_eval = create_coco_eval(\n",
    "            records=self._records,\n",
    "            preds=self._preds,\n",
    "            metric_type=self.metric_type.value,\n",
    "            iou_thresholds=self.iou_thresholds,\n",
    "            show_pbar=self.show_pbar,\n",
    "        )\n",
    "        coco_eval.params.catIds = self.class_ids #<== Add this row!!!!!!!!!!\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "\n",
    "\n",
    "    with CaptureStdout(propagate_stdout=self.print_summary):\n",
    "        coco_eval.summarize()\n",
    "    stats = coco_eval.stats\n",
    "    logs = {\n",
    "        \"AP (IoU=0.50:0.95) area=all\": stats[0],\n",
    "        \"AP (IoU=0.50) area=all\": stats[1],\n",
    "        \"AP (IoU=0.75) area=all\": stats[2],\n",
    "        \"AP (IoU=0.50:0.95) area=small\": stats[3],\n",
    "        \"AP (IoU=0.50:0.95) area=medium\": stats[4],\n",
    "        \"AP (IoU=0.50:0.95) area=large\": stats[5],\n",
    "        \"AR (IoU=0.50:0.95) area=all maxDets=1\": stats[6],\n",
    "        \"AR (IoU=0.50:0.95) area=all maxDets=10\": stats[7],\n",
    "        \"AR (IoU=0.50:0.95) area=all maxDets=100\": stats[8],\n",
    "        \"AR (IoU=0.50:0.95) area=small maxDets=100\": stats[9],\n",
    "        \"AR (IoU=0.50:0.95) area=medium maxDets=100\": stats[10],\n",
    "        \"AR (IoU=0.50:0.95) area=large maxDets=100\": stats[11],\n",
    "    }\n",
    "    self._reset()\n",
    "    return logs\n",
    "   \n",
    "class COCOMetric_Chair(COCOMetric_perclass):class_ids = [1] \n",
    "class COCOMetric_Couch(COCOMetric_perclass):class_ids = [2] \n",
    "class COCOMetric_TV(COCOMetric_perclass):class_ids = [3] \n",
    "class COCOMetric_Remote(COCOMetric_perclass):class_ids = [4] \n",
    "class COCOMetric_Book(COCOMetric_perclass):class_ids = [5] \n",
    "class COCOMetric_Vase(COCOMetric_perclass):class_ids = [6] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt\n",
    "# def log_predictions(learn):\n",
    "#     \"Log a Table with model predictions\"\n",
    "#     samples, outputs, predictions = get_predictions(learn)\n",
    "#     table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
    "#     wandb.log({\"pred_table\":table})\n",
    "\n",
    "# def log_final_metrics(learn):\n",
    "#     scores = learn.validate()\n",
    "#     metric_names = ['final_loss'] + [f'final_{x.name}' for x in learn.metrics]\n",
    "#     final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "#     for k,v in final_results.items(): \n",
    "#         wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, processed_dataset_dir=None):\n",
    "    set_seed(config.seed, reproducible=True)\n",
    "    run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=config)\n",
    "\n",
    "    config = wandb.config\n",
    "\n",
    "    if processed_dataset_dir is None:\n",
    "      processed_dataset_dir = download_data()\n",
    "\n",
    "    train_ds, valid_ds , parser = get_data(processed_dataset_dir, bs=config.batch_size, image_size=config.img_size, augment=config.augment)\n",
    "    # metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "    metrics = [COCOMetric_Chair(), COCOMetric_Couch(), \\\n",
    "                COCOMetric_TV(), COCOMetric_Remote(), COCOMetric_Book(), COCOMetric_Vase(), COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "    model_type, backbone, extra_args = select_model(config.arch, config.img_size)\n",
    "\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args)  \n",
    "    # Data Loaders\n",
    "    train_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=10, shuffle=True)\n",
    "    valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=4, shuffle=False)\n",
    "    learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics, cbs=[WandbCallback(log_dataset=True, log_model=True), SaveModelCallback(fname=f'run-{wandb.run.id}-model', monitor='miou')])\n",
    "    learn.fine_tune(config.epochs, config.lr,  freeze_epochs=1)\n",
    "\n",
    "    # Infer\n",
    "    infer_dl = model_type.infer_dl(valid_ds, batch_size=8, shuffle=False)\n",
    "    preds = model_type.predict_from_dl(model, infer_dl, keep_images=True)\n",
    "    wandb_images = wandb_img_preds(preds, add_ground_truth=True) \n",
    "    wandb.log({\"Predicted images\": wandb_images})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(train_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-ice",
   "language": "python",
   "name": "wandb-ice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
